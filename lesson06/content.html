
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lesson 06: Classification by a Neural Network using Keras &#8212; deeplearning in 540 minutes  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bonus Lesson: How did we train" href="../lesson07/content.html" />
    <link rel="prev" title="Lesson 05: Introduction Deep Learning" href="../lesson05/content.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="lesson-06-classification-by-a-neural-network-using-keras">
<h1>Lesson 06: Classification by a Neural Network using Keras<a class="headerlink" href="#lesson-06-classification-by-a-neural-network-using-keras" title="Permalink to this headline">¶</a></h1>
<p>All content is taken from <a class="reference external" href="https://carpentries-incubator.github.io/deep-learning-intro/02-keras/index.html">this lesson</a>.</p>
<ul class="simple">
<li><p><strong>Preface</strong> describing the inner workings of an artificial neural network (Multi-layer perceptron)</p></li>
<li><p><strong>Part 1</strong> creates a neural network using the <code class="docutils literal notranslate"><span class="pre">keras</span></code> interface in <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code></p></li>
<li><p><strong>Part 2</strong> continues to look at the training history, performs a prediction and constructs a confusion matrix from it</p></li>
</ul>
<div class="section" id="check-your-learning">
<h2>Check Your Learning<a class="headerlink" href="#check-your-learning" title="Permalink to this headline">¶</a></h2>
<div class="admonition-exercise-1-preface admonition">
<p class="admonition-title">Exercise 1 / Preface</p>
<p>The architecture presented in the video is often referred to as a feed-forward network. Come up with reasons why this might be the case? Compare your answers with the mentor.</p>
</div>
<details>
<summary>Solution</summary><div class="highlight-rst notranslate"><div class="highlight"><pre><span></span>Because the data is fed in a forward fashion through the network, from inputs to outputs.
</pre></div>
</div>
</details><div class="admonition-exercise-2-preface admonition">
<p class="admonition-title">Exercise 2 / Preface</p>
<p>You have created a neural network that takes <code class="docutils literal notranslate"><span class="pre">8</span></code> values as input. The network has two hidden (dense) layers of <code class="docutils literal notranslate"><span class="pre">10</span></code> neurons each. The output layer has size <code class="docutils literal notranslate"><span class="pre">3</span></code> and predicts 3 values. How many parameters does this network have which need to be optimized during training?</p>
<ol class="arabic simple">
<li><p>21</p></li>
<li><p>233</p></li>
<li><p>210</p></li>
<li><p>54</p></li>
</ol>
</div>
<details>
<summary>Solution</summary><div class="highlight-rst notranslate"><div class="highlight"><pre><span></span><span class="m">1.</span> (please reconsider) you have added all numbers in the exercise
<span class="m">2.</span> (correct) layer1: 8<span class="ge">*10 + 10 = 80, layer2: 10*</span>10+10=110; output: 10*3+3=33
<span class="m">3.</span> (please reconsider) you omitted the bias terms
<span class="m">4.</span> (please reconsider) you have added dimensionalities instead of multiplying them to obtain the size of the matrix
</pre></div>
</div>
</details><div class="admonition-exercise-1-part-1 admonition">
<p class="admonition-title">Exercise 1 / Part 1</p>
<p>Take a look at the training and test set we created. Run the <code class="docutils literal notranslate"><span class="pre">sklearn.metrics.train_test_split</span></code> function multiple times with different parameters, e.g. vary the <code class="docutils literal notranslate"><span class="pre">random_state</span></code>, switch <code class="docutils literal notranslate"><span class="pre">stratify</span></code>.</p>
<ul class="simple">
<li><p>How many samples do the training and test sets have each time?</p></li>
<li><p>Are the classes in the training set well balanced compared to the output of <code class="docutils literal notranslate"><span class="pre">penguin_features.species_.value_counts()</span></code>?</p></li>
</ul>
</div>
<div class="admonition-exercise-2-part-1 admonition">
<p class="admonition-title">Exercise 2 / Part 1</p>
<p>With the code snippets in the video, we defined a keras model with 1 hidden layer with 10 neurons and an output layer with 3 neurons.</p>
<ul class="simple">
<li><p>recap: How many parameters does the resulting model have?</p></li>
<li><p>What happens to the number of parameters if we increase or decrease the number of neurons in the hidden layer?</p></li>
<li><p>Ask your neighbor to tell you a choice of layer number and layer width. Predict how many parameters will be needed. Then implement this and check!</p></li>
</ul>
</div>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<div class="section" id="exercise-1">
<h3>Exercise 1<a class="headerlink" href="#exercise-1" title="Permalink to this headline">¶</a></h3>
<p>The goal of this exercise is to fit a neural network to predict wine classes from the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html">sklearn wine dataset</a>.</p>
<p>Please consider the following aspects when solving this exercise:</p>
<ol class="arabic simple">
<li><p>The dataset can be loaded via <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">sklearn.datasets</span> <span class="pre">import</span> <span class="pre">load_wine;</span> <span class="pre">dataset</span> <span class="pre">=</span> <span class="pre">load_wine()</span></code>.
* Consider <code class="docutils literal notranslate"><span class="pre">print(dataset['DESCR'])</span></code> for more information about the dataset.
* <code class="docutils literal notranslate"><span class="pre">dataset['data']</span></code> contains the features which can be used as input data.
* <code class="docutils literal notranslate"><span class="pre">dataset['target']</span></code> contains the wine class labels.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pd.get_dummies</span></code> is helpful to obtain a one-hot encoded version of class labels.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> should be performed as usual.</p></li>
<li><p>When inspecting the features, you will realize that they all have different number ranges.
Hence, normalizing the data is required.
The <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">StandardScaler</a>
might be handy.</p></li>
<li><p>Regarding the network architecture, it’s best to start small (in terms of number of layers and
number of neurons) and only increase if performance is not sufficient. This helps to speed up
the training process.</p></li>
<li><p>If you need help with the code to set up and fit the neural network, please consider the lecture notes
about the penguin dataset; it’s quite similar.</p></li>
<li><p>Finally, when you are satisfied with the training process, assess the performance of your network
with help of the test set (confusion matrix, accuracy, etc).</p></li>
</ol>
<div class="section" id="bonus-1">
<h4>Bonus 1<a class="headerlink" href="#bonus-1" title="Permalink to this headline">¶</a></h4>
<p>It’s great to see the loss decreasing during training, but given a certain loss value, it’s still not
easy to judge how well the model <em>actually</em> performs.
It would be nice to observe higher level metrics, such as accuracy for example.
Fortunately, the <code class="docutils literal notranslate"><span class="pre">model.compile</span></code> method has a parameter which allows for adding such <code class="docutils literal notranslate"><span class="pre">metrics</span></code>.
These will eventually be stored in the fit <code class="docutils literal notranslate"><span class="pre">history</span></code>, just like the <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p>
<p>The goal of this exercise is to add accuracy as a metric when fitting the model.
Then the accuracy can be plotted for each epoch, similar to the loss value.
For more information, please consider the documentation of the
<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile">model.compile method</a>.</p>
<p>What other metrics that are useful for classification could you add?
Consider <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics">tf.keras.metrics</a>
for suggestions.</p>
</div>
</div>
<div class="section" id="exercise-2">
<h3>Exercise 2<a class="headerlink" href="#exercise-2" title="Permalink to this headline">¶</a></h3>
<p>The goal of this exercise is to train a neural network to predict binary class labels on a synthetic
dataset and compare the results to those obtained with a linear classifier.</p>
<p>The dataset can be found <a class="reference external" href="https://deeplearning540.github.io/lesson06/exc2/data.csv">here</a>.
It contains 2 columns <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> and an additional <code class="docutils literal notranslate"><span class="pre">target</span></code> column containing the class labels
(either <code class="docutils literal notranslate"><span class="pre">0</span></code> or <code class="docutils literal notranslate"><span class="pre">1</span></code>). The dataset can be visualized via
<code class="docutils literal notranslate"><span class="pre">sns.scatterplot(data=data_frame,</span> <span class="pre">x='x',</span> <span class="pre">y='y',</span> <span class="pre">hue='target')</span></code>.</p>
<p>The goal is to train a neural network, similar to Exercise 1, to predict the class labels of the dataset.</p>
<div class="section" id="id1">
<h4>Bonus 1<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>Try to use a linear classifier, such as
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html">RidgeClassifier</a>
to make predictions about the class labels. You can use the function below to visualize the predictions and ground truth labels:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">plot_prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">left</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Ground truth labels&#39;</span><span class="p">)</span>
    <span class="n">left</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">right</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Predicted labels&#39;</span><span class="p">)</span>
    <span class="n">right</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">c</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>You will find that the performance of the linear classifier is not very good.
How can we still use a linear classifier and get similarly good performance as for the neural network?</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Hint: Similar to how we scaled the input data for the wine dataset using the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>, we are
free to transform the data before feeding it to the linear classifier. A particular coordinate transformation
might be useful to make this a linear problem.</p>
</div>
<p>In the light of your findings, discuss in what situations a neural network might be more useful than a more
simple method such as a linear classifier, and vice versa.
What is a particular advantage of neural networks
(think about <a class="reference external" href="https://en.wikipedia.org/wiki/Feature_engineering">Feature engineering</a>)?</p>
</div>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">deeplearning in 540 minutes</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Lesson Modules</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../lesson_01/content.html">Lesson 01: Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson02/content.html">Lesson 02: Enter Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson03/content.html">Lesson 03: From Clustering To Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson04/content.html">Lesson 04: Classification Performance ROCs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson05/content.html">Lesson 05: Introduction Deep Learning</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Lesson 06: Classification by a Neural Network using Keras</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#check-your-learning">Check Your Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../lesson07/content.html">Bonus Lesson: How did we train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson08/content.html">Lesson 07: Monitor the training process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson09/content.html">Lesson 08: Networks are like onions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extras</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../extras/design.html">Lesson Design</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deprecated Material (will be removed in the next release)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../_lesson01/content.html">Deprecated Lesson 01: Diving into Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_lesson05/content.html">Deprecated Lesson 05: Neural Networks as Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_lesson06/content.html">Deprecated Lesson 06: How did we train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_lesson07/content.html">Deprecated Lesson 07: CNNs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_lesson08/content.html">Deprecated Lesson 08: Capstone</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../lesson05/content.html" title="previous chapter">Lesson 05: Introduction Deep Learning</a></li>
      <li>Next: <a href="../lesson07/content.html" title="next chapter">Bonus Lesson: How did we train</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Peter Steinbach.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.2.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/lesson06/content.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>